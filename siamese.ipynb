{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "siamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboelela924/siameseCovid19/blob/master/siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1x8l3mddOq9"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-NUsPrMVpw8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import functools\n",
        "import cv2 \n",
        "import os\n",
        "from random import randint,sample\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from sklearn.utils import class_weight\n",
        "from imutils import build_montages\n",
        "from sklearn import svm\n",
        "from tensorflow.keras.applications.densenet import DenseNet169\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTaXB-BVpxu"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from imutils.paths import list_images\n",
        "import argparse\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "untN7u-mdPoU"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QNBFgApdXFU"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFmj-I-3tTIX"
      },
      "source": [
        "\n",
        "BASE_OUTPUT = \"/content/drive/MyDrive/DL\"\n",
        "\n",
        "con_MODEL_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"contrastive_siamese_model\"])\n",
        "con_PLOT_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"contrastive_plot.png\"])\n",
        "\n",
        "con_MODEL_PATH_ = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"contrastive_siamese_model_\"])\n",
        "con_PLOT_PATH_ = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"contrastive_plot_.png\"])\n",
        "\n",
        "tri_MODEL_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"triplet_siamese_model_\"])\n",
        "tri_PLOT_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "    \"triplet_plot_.png\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izHQEEfU6Aiq"
      },
      "source": [
        "!kaggle datasets download -d xhlulu/densenet-keras\n",
        "\n",
        "!unzip -qq /content/densenet-keras.zip\n",
        "\n",
        "Network_Weight=\"/content/DenseNet-BC-169-32-no-top.h5\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJehyhwIVpxI"
      },
      "source": [
        "IMG_SHAPE = (224,224,3)\n",
        "features=50\n",
        "pre_trained_model = DenseNet169(input_shape = IMG_SHAPE, \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "pre_trained_model.load_weights(Network_Weight)\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False  #to make the layers to Freeze Weights\n",
        "pre_trained_model.summary()\n",
        "flatten = tf.keras.layers.Flatten()(pre_trained_model.layers[-2].output)\n",
        "dense1 = tf.keras.layers.Dense(125, activation='relu')(flatten)\n",
        "dense1 = tf.keras.layers.BatchNormalization()(dense1)\n",
        "drop = tf.keras.layers.Dropout(0.25)(dense1)\n",
        "dense2 = tf.keras.layers.Dense(75, activation=\"relu\")(drop)\n",
        "dense2 = tf.keras.layers.BatchNormalization()(dense2)\n",
        "new_output = tf.keras.layers.Dense(features)(dense2)\n",
        "  \n",
        "featureExtractor = tf.keras.Model(inputs = pre_trained_model.input,outputs=new_output)\n",
        "featureExtractor.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_wb4uHx-S0"
      },
      "source": [
        "class DataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, path,\n",
        "                 batch_size,\n",
        "                 image_size,\n",
        "                 exa,\n",
        "                 loss_type='contrastive'\n",
        "                 ):\n",
        "        \n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size=image_size\n",
        "        self.loss_type=loss_type\n",
        "        self.exa=exa\n",
        "        self.classes= self.list_full_paths(path)\n",
        "    \n",
        "    def list_full_paths(self,directory):\n",
        "      return [os.path.join(directory, file) for file in os.listdir(directory)]\n",
        "    def get_img(self,path):\n",
        "      image=np.asarray(cv2.imread(path))/255\n",
        "      if image.ndim==2:\n",
        "        image=np.stack((image,)*3, axis=-1)\n",
        "\n",
        "\n",
        "      rand_aug=randint(0,2)\n",
        "\n",
        "\n",
        "      if rand_aug==0:\n",
        "        pass\n",
        "      elif rand_aug==1:\n",
        "        image=np.fliplr(image)\n",
        "      else:\n",
        "        image=np.flipud(image)\n",
        "\n",
        "\n",
        "      return cv2.resize(image, dsize=(self.image_size,self.image_size))\n",
        "\n",
        "    def __get_in_out(self):\n",
        "\n",
        "        label=randint(0,1)        \n",
        "        if self.loss_type =='Triplet':\n",
        "          pos_neg=sample(self.classes, 2)  \n",
        "\n",
        "          list_pos=self.list_full_paths(pos_neg[0])\n",
        "          anc_pos=sample(list_pos, 2)\n",
        "\n",
        "          list_neg=self.list_full_paths(pos_neg[1])\n",
        "          neg=sample(list_neg, 1)\n",
        "          \n",
        "          return self.get_img(anc_pos[0]),self.get_img(anc_pos[1]),self.get_img(neg[0])\n",
        "\n",
        "        else:\n",
        "          if label==0:\n",
        "            pos_neg=sample(self.classes, 2)\n",
        "\n",
        "            list_pos=self.list_full_paths(pos_neg[0])\n",
        "            pos=sample(list_pos, 1)\n",
        "\n",
        "            list_neg=self.list_full_paths(pos_neg[1])\n",
        "            neg=sample(list_neg, 1)\n",
        "\n",
        "            return self.get_img(pos[0]),self.get_img(neg[0]),label\n",
        "\n",
        "          else:\n",
        "            pos=sample(self.classes,1 )\n",
        "\n",
        "            list_pos=self.list_full_paths(pos[0])\n",
        "            pos=sample(list_pos, 2)\n",
        "\n",
        "            return self.get_img(pos[0]),self.get_img(pos[1]),label\n",
        "            \n",
        "\n",
        "\n",
        "    def __get_data(self):\n",
        "        if self.loss_type =='Triplet':    \n",
        "          x_1_batch=np.empty((self.batch_size,self.image_size,self.image_size,3))\n",
        "          x_2_batch=np.empty((self.batch_size,self.image_size,self.image_size,3))\n",
        "          x_3_batch=np.empty((self.batch_size,self.image_size,self.image_size,3))\n",
        "          y_batch=np.zeros((self.batch_size))\n",
        "          for id  in range(self.batch_size):\n",
        "            x1,x2,x3=self.__get_in_out()\n",
        "            x_1_batch[id,]=x1\n",
        "            x_2_batch[id,]=x2\n",
        "            x_3_batch[id,]=x3\n",
        "          return [x_1_batch,x_2_batch,x_3_batch],y_batch\n",
        "\n",
        "        else:\n",
        "          x_1_batch=np.empty((self.batch_size,self.image_size,self.image_size,3))\n",
        "          x_2_batch=np.empty((self.batch_size,self.image_size,self.image_size,3))\n",
        "          y_batch=np.empty((self.batch_size))         \n",
        "          for id  in range(self.batch_size):\n",
        "            x1,x2,y=self.__get_in_out()\n",
        "            x_1_batch[id,]=x1\n",
        "            x_2_batch[id,]=x2\n",
        "            y_batch[id,]=y\n",
        "          return [x_1_batch,x_2_batch],y_batch\n",
        "        \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        x, y = self.__get_data() \n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return np.int(self.exa // self.batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J882dxRTmW4"
      },
      "source": [
        "def read_images(dataset_path):\n",
        "        imagepaths, labels = list(), list()\n",
        "\n",
        "        # An ID will be affected to each sub-folders by alphabetical order\n",
        "        label = 0\n",
        "\n",
        "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
        "        for c in classes:\n",
        "            c_dir = os.path.join(dataset_path, c)\n",
        "            walk = os.walk(c_dir).__next__()\n",
        "            print(walk)\n",
        "            # Add each image to the training set\n",
        "            for sample in walk[2][:50]:\n",
        "                # Only keeps jpeg images\n",
        "                if sample.endswith('.jpg') or sample.endswith('.jpeg'):\n",
        "                    imagepaths.append(os.path.join(c_dir, sample))\n",
        "                    labels.append(label)\n",
        "            label += 1\n",
        "        num_of_labels=label+1\n",
        "        return imagepaths, np.array(labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz87yAldVpxS"
      },
      "source": [
        "def make_pairs(images, labels):\n",
        "\n",
        "    pairImages = []\n",
        "    pairLabels = []\n",
        "    numClasses = len(np.unique(labels))\n",
        "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "    for idxA in range(len(images)):\n",
        "        currentImage = images[idxA]\n",
        "        label = labels[idxA]\n",
        "\n",
        "        idxB = np.random.choice(idx[label])\n",
        "        posImage = images[idxB]\n",
        "\n",
        "        pairImages.append([currentImage, posImage])\n",
        "        pairLabels.append([1])\n",
        "        negIdx = np.where(labels != label)[0]\n",
        "        negImage = images[np.random.choice(negIdx)]\n",
        "        pairImages.append([currentImage, negImage])\n",
        "        pairLabels.append([0])\n",
        "    return (np.array(pairImages), np.array(pairLabels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSWCNRCVpxY"
      },
      "source": [
        "def imread_array(imagesPath,imageShape):\n",
        "    images= list()\n",
        "    sizeArray=imagesPath.shape\n",
        "    imageShape=imageShape[0:2]\n",
        "    for row in range (sizeArray[0]):\n",
        "        imageA=cv2.imread(imagesPath[row][0])\n",
        "        imageA=cv2.resize(imageA,imageShape)\n",
        "        imageB=cv2.imread(imagesPath[row][1])\n",
        "        imageB=cv2.resize(imageB,imageShape)\n",
        "        images.append([imageA, imageB])\n",
        "    return np.array(images)        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0KVs1ZeZ7sD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zKjU0PFupuQ"
      },
      "source": [
        "from collections import defaultdict\n",
        "t = defaultdict(lambda: list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxtx0GAxsEa6"
      },
      "source": [
        "def createPredictionSet(data, labels, element_for_class=10):\n",
        "    unique_labels = set(labels)\n",
        "    image_for_label = defaultdict(lambda: [])\n",
        "    for i,img in enumerate(data):\n",
        "        if len(image_for_label[f\"{labels[i]}\"]) < element_for_class:\n",
        "            image_for_label[f\"{labels[i]}\"].append(img)\n",
        "        if sum([len(v) for v in image_for_label.values()]) >= len(unique_labels) * element_for_class:\n",
        "            break\n",
        "    return image_for_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgHHGdtvQUde"
      },
      "source": [
        "!kaggle datasets download -d prashant268/chest-xray-covid19-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdE6VNtQrZy"
      },
      "source": [
        "!unzip -qq chest-xray-covid19-pneumonia.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pTkMJrU-55"
      },
      "source": [
        "# !rm -r /content/Data/test/PNEUMONIA/\n",
        "# !rm -r /content/Data/train/PNEUMONIA/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42_zcgWyVpxc"
      },
      "source": [
        "(trainX, trainY) = read_images(r\"/content/Data/train\")\n",
        "(testX, testY) = read_images(r\"/content/Data/test\")\n",
        "(pairTrainPaths, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTestPaths, labelTest) = make_pairs(testX, testY)\n",
        "pairTrain=imread_array(pairTrainPaths,IMG_SHAPE)\n",
        "pairTest=imread_array(pairTestPaths,IMG_SHAPE)\n",
        "images = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XFiHMeMVpxd"
      },
      "source": [
        "for i in np.random.choice(np.arange(0, len(pairTrain)), size=(49,)):    \n",
        "    imageA=cv2.cvtColor(pairTrain[i][0], cv2.COLOR_BGR2GRAY)\n",
        "    imageA =cv2.resize(imageA, (28,28))\n",
        "    imageB =cv2.cvtColor(pairTrain[i][1], cv2.COLOR_BGR2GRAY)\n",
        "    imageB=cv2.resize(imageB,(28,28))\n",
        "    \n",
        "    label = labelTrain[i]\n",
        "    # to make it easier to visualize the pairs and their positive or\n",
        "    # negative annotations, we're going to \"pad\" the pair with four\n",
        "    # pixels along the top, bottom, and right borders, respectively\n",
        "    output = np.zeros((36, 60), dtype=\"uint8\")\n",
        "    pair = np.hstack([imageA, imageB])\n",
        "    output[4:32, 0:56] = pair\n",
        "    # set the text label for the pair along with what color we are\n",
        "    # going to draw the pair in (green for a \"positive\" pair and\n",
        "    # red for a \"negative\" pair)\n",
        "    text = \"neg\" if label[0] == 0 else \"pos\"\n",
        "    color = (0, 0, 255) if label[0] == 0 else (0, 255, 0)\n",
        "    # create a 3-channel RGB image from the grayscale pair, resize\n",
        "    # it from 60x36 to 96x51 (so we can better see it), and then\n",
        "    # draw what type of pair it is on the image\n",
        "    vis = cv2.merge([output] * 3)\n",
        "    vis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n",
        "    cv2.putText(vis, text, (2, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "        color, 2)\n",
        "    # add the pair visualization to our list of output images\n",
        "    images.append(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWn343saVpxh"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 51), (7, 7))[0]\n",
        "# show the output montage\n",
        "cv2_imshow( montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLScnwRVpxn"
      },
      "source": [
        "def distance(vectors):\n",
        "    (featsA, featsB) = vectors\n",
        "    cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
        "    out=(cosine_loss(featsA, featsB)+1)/5\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJIJZ7QdVpxp"
      },
      "source": [
        "def plot_training(H, plotPath):\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8wFqhnRJqwi"
      },
      "source": [
        "def contrastive_loss_(y, preds, margin=20):\n",
        "\n",
        "    y = tf.cast(y, preds.dtype)\n",
        "\n",
        "    squaredPreds = K.square(preds)\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAUrvql1Vpxq"
      },
      "source": [
        "def contrastive_loss(y, preds, margin=1):\n",
        "\n",
        "    y = tf.cast(y, preds.dtype)\n",
        "\n",
        "    squaredPreds = K.square(preds)\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdwq0nSII4gV"
      },
      "source": [
        "\n",
        "def Triplet_loss(vectors):\n",
        "    margin=1\n",
        "    (featsA, featsB,featsC) = vectors\n",
        "    D1=Lambda(distance)([featsA, featsB])\n",
        "    D2=Lambda(distance)([featsA, featsC])\n",
        "    loss=K.maximum(0.0,margin+D1-D2)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC_viCUaLHWY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLvOcS2FVpxs"
      },
      "source": [
        "imgA = tf.keras.Input(shape=IMG_SHAPE)\n",
        "imgB = tf.keras.Input(shape=IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "distance_out =Lambda(distance)([featsA, featsB])\n",
        "contrastive_model = tf.keras.Model(inputs=[imgA, imgB], outputs=distance_out)\n",
        "contrastive_model_ = tf.keras.Model(inputs=[imgA, imgB], outputs=distance_out)\n",
        "\n",
        "# contrastive_model = tf.keras.models.load_model(con_MODEL_PATH,custom_objects={'contrastive_loss':contrastive_loss})\n",
        "# contrastive_model_ = tf.keras.models.load_model(con_MODEL_PATH_,custom_objects={'contrastive_loss_':contrastive_loss_})\n",
        "\n",
        "contrastive_model.compile(loss=contrastive_loss, optimizer=\"adam\")\n",
        "\n",
        "contrastive_model_.compile(loss=contrastive_loss_, optimizer=\"adam\")\n",
        "\n",
        "imgA_1 = tf.keras.Input(shape=IMG_SHAPE)\n",
        "imgB_1 = tf.keras.Input(shape=IMG_SHAPE)\n",
        "imgC_1 = tf.keras.Input(shape=IMG_SHAPE)\n",
        "\n",
        "featsA_1 = featureExtractor(imgA_1)\n",
        "featsB_1 = featureExtractor(imgB_1)\n",
        "featsC_1 = featureExtractor(imgC_1)\n",
        "\n",
        "LOSS =Lambda(Triplet_loss)([featsA_1, featsB_1,featsC_1])\n",
        "Triplet_model = tf.keras.Model(inputs=[imgA_1, imgB_1,imgC_1], outputs=LOSS)\n",
        "def loss_(gt,est):\n",
        "  out=est-gt\n",
        "  return out\n",
        "opt=tf.keras.optimizers.Adam(\n",
        "    beta_1=0.7,\n",
        "    beta_2=0.8)\n",
        "# Triplet_model = tf.keras.models.load_model(tri_MODEL_PATH,custom_objects={'loss_':loss_})\n",
        "Triplet_model.compile(loss=loss_, optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUyTCZ_SXsy6"
      },
      "source": [
        "tf.keras.utils.plot_model(contrastive_model, show_shapes=True,rankdir='LB')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlxcMyaW8pc"
      },
      "source": [
        "tf.keras.utils.plot_model(Triplet_model, show_shapes=True,rankdir='LB')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6FEscryX-aN"
      },
      "source": [
        "image_len_wid=224\n",
        "BATCH_SIZE = 32*4\n",
        "EPOCHS = 16\n",
        "\n",
        "train_contras_gen=DataGen(path='/content/Data/train',batch_size=BATCH_SIZE,image_size=image_len_wid,exa=25*32)\n",
        "test_contras_gen=DataGen(path='/content/Data/test',batch_size=BATCH_SIZE,image_size=image_len_wid,exa=10*32)\n",
        "\n",
        "train_Triplet_gen=DataGen(path='/content/Data/train',batch_size=BATCH_SIZE,image_size=image_len_wid,loss_type='Triplet',exa=25*32)\n",
        "test_Triplet_gen=DataGen(path='/content/Data/test',batch_size=BATCH_SIZE,image_size=image_len_wid,loss_type='Triplet',exa=10*32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYYi1jeMDx6o"
      },
      "source": [
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=tri_MODEL_PATH, \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "#Triplet_model.trainable=True\n",
        "Triplet_history = Triplet_model.fit(\n",
        "    train_Triplet_gen,\n",
        "    validation_data=test_Triplet_gen,\n",
        "    validation_freq=2,\n",
        "    callbacks=checkpoint,\n",
        "    epochs=EPOCHS)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxHApTchh1OA"
      },
      "source": [
        " \n",
        "# plot the training history\n",
        "plot_training(Triplet_history, tri_PLOT_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMhZ8rsmVpxt"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=con_MODEL_PATH, \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "contrastive_history = contrastive_model.fit(\n",
        "    train_contras_gen,\n",
        "    validation_data=test_contras_gen,\n",
        "    validation_freq=2,\n",
        "    callbacks=checkpoint,\n",
        "    epochs=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iysz2tkt35eP"
      },
      "source": [
        "\n",
        "# plot the training history\n",
        "plot_training(contrastive_history, con_PLOT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVnJlmVlKdU3"
      },
      "source": [
        "checkpoint_ = tf.keras.callbacks.ModelCheckpoint(filepath=con_MODEL_PATH_, \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "contrastive_history_ = contrastive_model_.fit(\n",
        "    train_contras_gen,\n",
        "    validation_data=test_contras_gen,\n",
        "    validation_freq=2,\n",
        "    callbacks=checkpoint_,\n",
        "    epochs=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRgVPqayKk60"
      },
      "source": [
        "\n",
        "# plot the training history\n",
        "plot_training(contrastive_history_, con_PLOT_PATH_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X70-H2yT9FVL"
      },
      "source": [
        "con_siamese_model=contrastive_model.get_layer(index=2)\n",
        "con_siamese_model_=contrastive_model_.get_layer(index=2)\n",
        "\n",
        "tri_siamese_model=Triplet_model.get_layer(index=3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riKMdK7o4UsR"
      },
      "source": [
        "image=cv2.imread('/content/Data/test/COVID19/COVID19(460).jpg')\n",
        "print(image.shape)\n",
        "image=image/255\n",
        "image=cv2.resize(image,(224,224))\n",
        "image=np.expand_dims(image,axis=0)\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6qEK9GStMnc"
      },
      "source": [
        "x=con_siamese_model(image)\n",
        "print(x.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c63QaHmB96Cp"
      },
      "source": [
        "def createImagePairWithPredictionSet(image, prediction_set, image_shape=(224, 224)):\n",
        "    prediction_set_img = defaultdict(lambda: [])\n",
        "    prediction_set_img_pairs = defaultdict(lambda: [])\n",
        "    for key, value in prediction_set.items():\n",
        "        for img in value:\n",
        "            new_img = cv2.imread(img)\n",
        "            new_img = cv2.resize(new_img, image_shape)\n",
        "            # new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "            prediction_set_img[key].append(new_img)\n",
        "            \n",
        "    if isinstance(image, str):\n",
        "        test_img = cv2.imread(image)\n",
        "        test_img = cv2.resize(test_img, image_shape)\n",
        "        # test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        image = np.squeeze(image)\n",
        "        if image.shape != (224, 224):\n",
        "            test_img = cv2.resize(image, image_shape)\n",
        "            # test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            test_img = image  \n",
        "    \n",
        "    test_img = np.expand_dims(test_img, axis=0)\n",
        "    for key, value in prediction_set_img.items():\n",
        "        for img in value:\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "\n",
        "            prediction_set_img_pairs[key].append([test_img, img])\n",
        "    \n",
        "    return prediction_set_img_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EffaDrS1DB5F"
      },
      "source": [
        "prediction_data = createPredictionSet(trainX, trainY, element_for_class=20)\n",
        "predictions = []\n",
        "for i, test_img_path in enumerate(testX):\n",
        "    prediction_set_img_pairs = createImagePairWithPredictionSet(test_img_path, prediction_data)\n",
        "    highest_value_per_label = {}\n",
        "    for key, value in prediction_set_img_pairs.items():\n",
        "        key_output = []\n",
        "        for pair in value:\n",
        "            preds = contrastive_model.predict(pair)\n",
        "            key_output.append(preds[0][0])\n",
        "        highest_value_per_label[key] = np.min(key_output)\n",
        "    predictions.append(int(min(highest_value_per_label, key=highest_value_per_label.get)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8uT0stqZbbz"
      },
      "source": [
        "accuracy_score(testY, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fkak36JEFNx"
      },
      "source": [
        "def list_full_paths(directory):\n",
        "  return [os.path.join(directory, file) for file in os.listdir(directory)]\n",
        "\n",
        "def read_img(list_,wid_len,cha):\n",
        "  num=len(list_)\n",
        "  patch=np.empty((num,wid_len,wid_len,cha))\n",
        "  for i in range(num):\n",
        "    img=np.asarray(cv2.imread(list_[i]))/255\n",
        "    patch[i]=np.resize(img,(wid_len,wid_len,cha))\n",
        "\n",
        "  return patch\n",
        "example_per_class=400\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dNpeaND0hq2U"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "example_per_class=400\n",
        "list_train_COV=list_full_paths('/content/Data/train/COVID19')\n",
        "cov_example_path=sample(list_train_COV, example_per_class)\n",
        "cov_example=read_img(cov_example_path,image_len_wid,3)\n",
        "\n",
        "list_train_NON=list_full_paths('/content/Data/train/NORMAL')\n",
        "non_example_path=sample(list_train_NON, example_per_class)\n",
        "non_example=read_img(non_example_path,image_len_wid,3)\n",
        "\n",
        "list_train_PNEUMONIA=list_full_paths('/content/Data/train/PNEUMONIA')\n",
        "PNEUMONIA_example_path=sample(list_train_PNEUMONIA, example_per_class)\n",
        "PNEUMONIA_example=read_img(PNEUMONIA_example_path,image_len_wid,3)\n",
        "\n",
        "\n",
        "cov_vectors=tri_siamese_model.predict(cov_example)\n",
        "cov_label=np.full((np.shape(cov_vectors)[0]), 0, dtype=int)\n",
        "\n",
        "\n",
        "PNEUMONIA_vectors=tri_siamese_model.predict(PNEUMONIA_example)\n",
        "p_label=np.full((np.shape(PNEUMONIA_vectors)[0]), 1, dtype=int)\n",
        "\n",
        "non_vectors=tri_siamese_model.predict(non_example)\n",
        "non_label=np.full((np.shape(non_vectors)[0]), 2, dtype=int)\n",
        "\n",
        "x=np.concatenate((cov_vectors, PNEUMONIA_vectors,non_vectors), axis=0)\n",
        "y=np.concatenate((cov_label, p_label,non_label), axis=0)\n",
        "\n",
        "clf = svm.LinearSVC(tol=.000001)\n",
        "clf.fit(x, y)\n",
        "yy=clf.predict(x)\n",
        "\n",
        "o=yy-y\n",
        "print((o.size-np.count_nonzero(o))/1200)\n",
        "\n",
        "non_test_path=list_full_paths('/content/Data/test/NORMAL')\n",
        "cov_test_path=list_full_paths('/content/Data/test/COVID19')\n",
        "PNEUMONIA_test_path=list_full_paths('/content/Data/test/PNEUMONIA')\n",
        "\n",
        "test_non=read_img(non_test_path,image_len_wid,3)\n",
        "test_fea=tri_siamese_model.predict(test_non)\n",
        "non_pre=clf.predict(test_fea)\n",
        "\n",
        "unique, counts = np.unique(non_pre, return_counts=True)\n",
        "non_=dict(zip(unique, counts))\n",
        "print(non_)\n",
        "\n",
        "test_cov=read_img(cov_test_path,image_len_wid,3)\n",
        "test_cov_fea=tri_siamese_model.predict(test_cov)\n",
        "cov_pre=clf.predict(test_cov_fea)\n",
        "\n",
        "unique, counts = np.unique(cov_pre, return_counts=True)\n",
        "cov_=dict(zip(unique, counts))\n",
        "print(cov_)\n",
        "\n",
        "\n",
        "test_p=read_img(PNEUMONIA_test_path,image_len_wid,3)\n",
        "test_p_fea=tri_siamese_model.predict(test_p)\n",
        "pne_pre=clf.predict(test_p_fea)\n",
        "\n",
        "unique, counts = np.unique(pne_pre, return_counts=True)\n",
        "pne_=dict(zip(unique, counts))\n",
        "print(pne_)\n",
        "\n",
        "C=np.empty((3,3))\n",
        "C[1]=[pne_[0],pne_[1],pne_[2]]/(pne_[0]+pne_[1]+pne_[2])\n",
        "C[0]=[cov_[0],cov_[1],cov_[2]]/(cov_[0]+cov_[1]+cov_[2])\n",
        "C[2]=[non_[0],non_[1],non_[2]]/(non_[0]+non_[1]+non_[2])\n",
        "plt.imshow(C, cmap='gray', interpolation='nearest')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc0j8jY1h1EF"
      },
      "source": [
        "print(C)\n",
        "print(\"acc= \",(C[0,0]+C[1,1]+C[2,2])/np.sum(C))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVp-pA8NTiBW"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#example_per_class=400\n",
        "#list_train_COV=list_full_paths('/content/Data/train/COVID19')\n",
        "#cov_example_path=sample(list_train_COV, example_per_class)\n",
        "#cov_example=read_img(cov_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_NON=list_full_paths('/content/Data/train/NORMAL')\n",
        "# non_example_path=sample(list_train_NON, example_per_class)\n",
        "# non_example=read_img(non_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_PNEUMONIA=list_full_paths('/content/Data/train/PNEUMONIA')\n",
        "# PNEUMONIA_example_path=sample(list_train_PNEUMONIA, example_per_class)\n",
        "# PNEUMONIA_example=read_img(PNEUMONIA_example_path,image_len_wid,3)\n",
        "\n",
        "\n",
        "cov_vectors=con_siamese_model.predict(cov_example)\n",
        "cov_label=np.full((np.shape(cov_vectors)[0]), 0, dtype=int)\n",
        "\n",
        "\n",
        "PNEUMONIA_vectors=con_siamese_model.predict(PNEUMONIA_example)\n",
        "p_label=np.full((np.shape(PNEUMONIA_vectors)[0]), 1, dtype=int)\n",
        "\n",
        "non_vectors=con_siamese_model.predict(non_example)\n",
        "non_label=np.full((np.shape(non_vectors)[0]), 2, dtype=int)\n",
        "\n",
        "x=np.concatenate((cov_vectors, PNEUMONIA_vectors,non_vectors), axis=0)\n",
        "y=np.concatenate((cov_label, p_label,non_label), axis=0)\n",
        "\n",
        "clf = svm.LinearSVC(tol=.000001)\n",
        "clf.fit(x, y)\n",
        "yy=clf.predict(x)\n",
        "\n",
        "o=yy-y\n",
        "print((o.size-np.count_nonzero(o))/1200)\n",
        "\n",
        "# non_test_path=list_full_paths('/content/Data/test/NORMAL')\n",
        "# cov_test_path=list_full_paths('/content/Data/test/COVID19')\n",
        "# PNEUMONIA_test_path=list_full_paths('/content/Data/test/PNEUMONIA')\n",
        "\n",
        "#test_non=read_img(non_test_path,image_len_wid,3)\n",
        "test_fea=con_siamese_model.predict(test_non)\n",
        "non_pre=clf.predict(test_fea)\n",
        "\n",
        "unique, counts = np.unique(non_pre, return_counts=True)\n",
        "non_=dict(zip(unique, counts))\n",
        "print(non_)\n",
        "\n",
        "#test_cov=read_img(cov_test_path,image_len_wid,3)\n",
        "test_cov_fea=con_siamese_model.predict(test_cov)\n",
        "cov_pre=clf.predict(test_cov_fea)\n",
        "\n",
        "unique, counts = np.unique(cov_pre, return_counts=True)\n",
        "cov_=dict(zip(unique, counts))\n",
        "print(cov_)\n",
        "\n",
        "\n",
        "#test_p=read_img(PNEUMONIA_test_path,image_len_wid,3)\n",
        "test_p_fea=con_siamese_model.predict(test_p)\n",
        "pne_pre=clf.predict(test_p_fea)\n",
        "\n",
        "unique, counts = np.unique(pne_pre, return_counts=True)\n",
        "pne_=dict(zip(unique, counts))\n",
        "print(pne_)\n",
        "\n",
        "C=np.empty((3,3))\n",
        "C[1]=[pne_[0],pne_[1],pne_[2]]\n",
        "C[0]=[cov_[0],cov_[1],cov_[2]]\n",
        "C[2]=[non_[0],non_[1],non_[2]]\n",
        "plt.imshow(C, cmap='hot', interpolation='nearest')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEFakZSRTrCe"
      },
      "source": [
        "print(C)\n",
        "print(\"acc= \",(C[0,0]+C[1,1]+C[2,2])/np.sum(C))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GXD71VbfhvT"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#example_per_class=400\n",
        "#list_train_COV=list_full_paths('/content/Data/train/COVID19')\n",
        "#cov_example_path=sample(list_train_COV, example_per_class)\n",
        "#cov_example=read_img(cov_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_NON=list_full_paths('/content/Data/train/NORMAL')\n",
        "# non_example_path=sample(list_train_NON, example_per_class)\n",
        "# non_example=read_img(non_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_PNEUMONIA=list_full_paths('/content/Data/train/PNEUMONIA')\n",
        "# PNEUMONIA_example_path=sample(list_train_PNEUMONIA, example_per_class)\n",
        "# PNEUMONIA_example=read_img(PNEUMONIA_example_path,image_len_wid,3)\n",
        "\n",
        "\n",
        "cov_vectors=con_siamese_model_.predict(cov_example)\n",
        "cov_label=np.full((np.shape(cov_vectors)[0]), 0, dtype=int)\n",
        "\n",
        "\n",
        "PNEUMONIA_vectors=con_siamese_model_.predict(PNEUMONIA_example)\n",
        "p_label=np.full((np.shape(PNEUMONIA_vectors)[0]), 1, dtype=int)\n",
        "\n",
        "non_vectors=con_siamese_model_.predict(non_example)\n",
        "non_label=np.full((np.shape(non_vectors)[0]), 2, dtype=int)\n",
        "\n",
        "x=np.concatenate((cov_vectors, PNEUMONIA_vectors,non_vectors), axis=0)\n",
        "y=np.concatenate((cov_label, p_label,non_label), axis=0)\n",
        "\n",
        "clf = svm.LinearSVC(tol=.000001)\n",
        "clf.fit(x, y)\n",
        "yy=clf.predict(x)\n",
        "\n",
        "o=yy-y\n",
        "print((o.size-np.count_nonzero(o))/1200)\n",
        "\n",
        "# non_test_path=list_full_paths('/content/Data/test/NORMAL')\n",
        "# cov_test_path=list_full_paths('/content/Data/test/COVID19')\n",
        "# PNEUMONIA_test_path=list_full_paths('/content/Data/test/PNEUMONIA')\n",
        "\n",
        "#test_non=read_img(non_test_path,image_len_wid,3)\n",
        "test_fea=con_siamese_model_.predict(test_non)\n",
        "non_pre=clf.predict(test_fea)\n",
        "\n",
        "unique, counts = np.unique(non_pre, return_counts=True)\n",
        "non_=dict(zip(unique, counts))\n",
        "print(non_)\n",
        "\n",
        "#test_cov=read_img(cov_test_path,image_len_wid,3)\n",
        "test_cov_fea=con_siamese_model_.predict(test_cov)\n",
        "cov_pre=clf.predict(test_cov_fea)\n",
        "\n",
        "unique, counts = np.unique(cov_pre, return_counts=True)\n",
        "cov_=dict(zip(unique, counts))\n",
        "print(cov_)\n",
        "\n",
        "\n",
        "#test_p=read_img(PNEUMONIA_test_path,image_len_wid,3)\n",
        "test_p_fea=con_siamese_model_.predict(test_p)\n",
        "pne_pre=clf.predict(test_p_fea)\n",
        "\n",
        "unique, counts = np.unique(pne_pre, return_counts=True)\n",
        "pne_=dict(zip(unique, counts))\n",
        "print(pne_)\n",
        "\n",
        "C=np.empty((3,3))\n",
        "C[1]=[pne_[0],pne_[1],pne_[2]]\n",
        "C[0]=[cov_[0],cov_[1],cov_[2]]\n",
        "C[2]=[non_[0],non_[1],non_[2]]\n",
        "plt.imshow(C, cmap='hot', interpolation='nearest')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_0n8UoBfk5p"
      },
      "source": [
        "print(C)\n",
        "print(\"acc= \",(C[0,0]+C[1,1]+C[2,2])/np.sum(C))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HWL55cTaSJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#example_per_class=400\n",
        "#list_train_COV=list_full_paths('/content/Data/train/COVID19')\n",
        "#cov_example_path=sample(list_train_COV, example_per_class)\n",
        "#cov_example=read_img(cov_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_NON=list_full_paths('/content/Data/train/NORMAL')\n",
        "# non_example_path=sample(list_train_NON, example_per_class)\n",
        "# non_example=read_img(non_example_path,image_len_wid,3)\n",
        "\n",
        "# list_train_PNEUMONIA=list_full_paths('/content/Data/train/PNEUMONIA')\n",
        "# PNEUMONIA_example_path=sample(list_train_PNEUMONIA, example_per_class)\n",
        "# PNEUMONIA_example=read_img(PNEUMONIA_example_path,image_len_wid,3)\n",
        "\n",
        "\n",
        "cov_vectors=np.concatenate((con_siamese_model.predict(cov_example),con_siamese_model_.predict(cov_example),tri_siamese_model.predict(cov_example)),axis=1)\n",
        "cov_label=np.full((np.shape(cov_vectors)[0]), 0, dtype=int)\n",
        "\n",
        "\n",
        "PNEUMONIA_vectors=np.concatenate((con_siamese_model.predict(PNEUMONIA_example),con_siamese_model_.predict(PNEUMONIA_example),tri_siamese_model.predict(PNEUMONIA_example)),axis=1)\n",
        "p_label=np.full((np.shape(PNEUMONIA_vectors)[0]), 1, dtype=int)\n",
        "\n",
        "non_vectors=np.concatenate((con_siamese_model.predict(non_example),con_siamese_model_.predict(non_example),tri_siamese_model.predict(non_example)),axis=1)\n",
        "non_label=np.full((np.shape(non_vectors)[0]), 2, dtype=int)\n",
        "\n",
        "x=np.concatenate((cov_vectors, PNEUMONIA_vectors,non_vectors), axis=0)\n",
        "y=np.concatenate((cov_label, p_label,non_label), axis=0)\n",
        "\n",
        "clf = svm.LinearSVC(tol=.000001)\n",
        "clf.fit(x, y)\n",
        "yy=clf.predict(x)\n",
        "\n",
        "o=yy-y\n",
        "print((o.size-np.count_nonzero(o))/1200)\n",
        "\n",
        "# non_test_path=list_full_paths('/content/Data/test/NORMAL')\n",
        "# cov_test_path=list_full_paths('/content/Data/test/COVID19')\n",
        "# PNEUMONIA_test_path=list_full_paths('/content/Data/test/PNEUMONIA')\n",
        "\n",
        "#test_non=read_img(non_test_path,image_len_wid,3)\n",
        "test_fea=np.concatenate((con_siamese_model.predict(test_non),con_siamese_model_.predict(test_non),tri_siamese_model.predict(test_non)),axis=1)\n",
        "non_pre=clf.predict(test_fea)\n",
        "\n",
        "unique, counts = np.unique(non_pre, return_counts=True)\n",
        "non_=dict(zip(unique, counts))\n",
        "print(non_)\n",
        "\n",
        "#test_cov=read_img(cov_test_path,image_len_wid,3)\n",
        "test_cov_fea=np.concatenate((con_siamese_model.predict(test_cov),con_siamese_model_.predict(test_cov),tri_siamese_model.predict(test_cov)),axis=1)\n",
        "cov_pre=clf.predict(test_cov_fea)\n",
        "\n",
        "unique, counts = np.unique(cov_pre, return_counts=True)\n",
        "cov_=dict(zip(unique, counts))\n",
        "print(cov_)\n",
        "\n",
        "\n",
        "#test_p=read_img(PNEUMONIA_test_path,image_len_wid,3)\n",
        "test_p_fea=np.concatenate((con_siamese_model.predict(test_p),con_siamese_model_.predict(test_p),tri_siamese_model.predict(test_p)),axis=1)\n",
        "pne_pre=clf.predict(test_p_fea)\n",
        "\n",
        "unique, counts = np.unique(pne_pre, return_counts=True)\n",
        "pne_=dict(zip(unique, counts))\n",
        "print(pne_)\n",
        "\n",
        "C=np.empty((3,3))\n",
        "C[1]=[pne_[0],pne_[1],pne_[2]]\n",
        "C[0]=[cov_[0],cov_[1],cov_[2]]\n",
        "C[2]=[non_[0],non_[1],non_[2]]\n",
        "plt.imshow(C, cmap='hot', interpolation='nearest')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqyfnszIegb"
      },
      "source": [
        "print(C)\n",
        "print(\"acc= \",(C[0,0]+C[1,1]+C[2,2])/np.sum(C))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4rianaSIfzl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}